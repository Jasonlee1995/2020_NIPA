{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataset import *\n",
    "from train import *\n",
    "\n",
    "import csv, random\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "random.seed(1234)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir = '../../data/.train/.task148/data/train/images/'\n",
    "train_csv = '../../data/.train/.task148/data/train/train.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 4800\n",
      "1 1011\n",
      "2 4734\n",
      "3 29\n",
      "4 29\n"
     ]
    }
   ],
   "source": [
    "distributions = {}\n",
    "labels = ['10_콘크리트외벽', '20_조적외벽', '30_판넬외벽', '40_유리외벽', '50_기타외벽']\n",
    "idxs = {29: ['0', '1', '2'], 31: ['0', '1'], 32: ['0', '1'], 36: ['', '부속건축물', '주건축물'], \n",
    "        44: ['', ' ', '강파이프구조', '경량철골구조', '공업화박판강구조(PEB)', '기타강구조', '기타구조', '기타조적구조', '기타철골철근콘크리트구조', '기타콘크리트구조', '목구조', '벽돌구조', '블록구조', '석구조', '시멘트블럭조', '일반목구조', '일반철골구조', '조립식판넬조', '조적구조', '철골구조', '철골철근콘크리트구조', '철골철근콘크리트합성구조', '철골콘크리트구조', '철근콘크리트구조', '콘크리트구조', '통나무구조', '트러스구조', '프리케스트콘크리트구조'], \n",
    "        50: ['', ' ', '(철근)콘크리트', '기와', '기타지붕', '슬레이트']}\n",
    "\n",
    "with open(train_csv, 'r') as csvfile:\n",
    "    for i, line in enumerate(csv.reader(csvfile)):\n",
    "        if i != 0:\n",
    "            ID = line[0]\n",
    "            usage_list = []\n",
    "            for idx in idxs:\n",
    "                usage = [0]*len(idxs[idx])\n",
    "                usage[idxs[idx].index(line[idx])] = 1\n",
    "                usage_list += usage\n",
    "            target = line[67]\n",
    "            target = labels.index(target)\n",
    "            \n",
    "            if target not in distributions: distributions[target] = []\n",
    "            distributions[target].append((ID, tuple(usage_list), target))\n",
    "\n",
    "            \n",
    "distributions[0] = random.sample(distributions[0], 4800)\n",
    "#distributions[4] = random.sample(distributions[4], 4800)\n",
    "\n",
    "for distribution in sorted(distributions):\n",
    "    print(distribution, len(distributions[distribution]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7954 2649\n"
     ]
    }
   ],
   "source": [
    "train_set = set()\n",
    "val_set = set()\n",
    "\n",
    "for i in range(len(labels)):\n",
    "    temp = random.sample(distributions[i], len(distributions[i])//4)\n",
    "    train_set.update(set(distributions[i])-set(temp))\n",
    "    val_set.update(temp)\n",
    "    \n",
    "train = list(train_set)\n",
    "val = list(val_set)\n",
    "\n",
    "print(len(train), len(val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "\n",
    "epochs = 10\n",
    "lr = 0.0001\n",
    "weight_decay = 0.000001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transform = transforms.Compose([\n",
    "    transforms.Resize((256, 256)),\n",
    "    transforms.RandomCrop(224),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.5231, 0.5493, 0.5485], std=[0.2502, 0.2544, 0.2786])])\n",
    "\n",
    "val_transform = transforms.Compose([\n",
    "    transforms.Resize((256, 256)),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.5231, 0.5493, 0.5485], std=[0.2502, 0.2544, 0.2786])])\n",
    "\n",
    "\n",
    "train_dataset = Train_148(infos=train, transform=train_transform)\n",
    "val_dataset = Train_148(infos=val, transform=val_transform)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = torch.utils.data.DataLoader(val_dataset, batch_size=128, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Baseline(num_input=len(usage_list), num_classes=len(labels), save='./new_')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 Started...\n",
      "Best Model Saved\n",
      "Iteration : 10 - Train Loss : 0.752041, Val Loss : 0.934556, Train F1 : 0.492997, Val F1 : 0.305145\n",
      "Best Model Saved\n",
      "Iteration : 20 - Train Loss : 0.624299, Val Loss : 0.773456, Train F1 : 0.562963, Val F1 : 0.316333\n",
      "Best Model Saved\n",
      "Iteration : 30 - Train Loss : 0.512634, Val Loss : 0.669628, Train F1 : 0.582011, Val F1 : 0.325233\n",
      "Best Model Saved\n",
      "Iteration : 40 - Train Loss : 0.824274, Val Loss : 0.612024, Train F1 : 0.480368, Val F1 : 0.331608\n",
      "Best Model Saved\n",
      "Iteration : 50 - Train Loss : 1.133567, Val Loss : 0.583231, Train F1 : 0.293300, Val F1 : 0.335981\n",
      "Best Model Saved\n",
      "Iteration : 60 - Train Loss : 0.426888, Val Loss : 0.585390, Train F1 : 0.608148, Val F1 : 0.337836\n",
      "Best Model Saved\n",
      "Iteration : 70 - Train Loss : 0.540961, Val Loss : 0.571628, Train F1 : 0.547619, Val F1 : 0.349114\n",
      "Best Model Saved\n",
      "Iteration : 80 - Train Loss : 0.511513, Val Loss : 0.572703, Train F1 : 0.567766, Val F1 : 0.361957\n",
      "Best Model Saved\n",
      "Iteration : 90 - Train Loss : 0.394988, Val Loss : 0.568680, Train F1 : 0.612454, Val F1 : 0.375597\n",
      "Best Model Saved\n",
      "Iteration : 100 - Train Loss : 0.735439, Val Loss : 0.571151, Train F1 : 0.378734, Val F1 : 0.375708\n",
      "Best Model Saved\n",
      "Iteration : 110 - Train Loss : 0.676353, Val Loss : 0.565028, Train F1 : 0.531106, Val F1 : 0.382935\n",
      "Best Model Saved\n",
      "Iteration : 120 - Train Loss : 0.632831, Val Loss : 0.570631, Train F1 : 0.555432, Val F1 : 0.396469\n",
      "Iteration : 130 - Train Loss : 0.525868, Val Loss : 0.571375, Train F1 : 0.812739, Val F1 : 0.377417\n",
      "Iteration : 140 - Train Loss : 0.470964, Val Loss : 0.573846, Train F1 : 0.546237, Val F1 : 0.391193\n",
      "Best Model Saved\n",
      "Iteration : 150 - Train Loss : 0.647254, Val Loss : 0.571741, Train F1 : 0.571429, Val F1 : 0.400449\n",
      "Iteration : 160 - Train Loss : 0.540644, Val Loss : 0.574392, Train F1 : 0.766593, Val F1 : 0.395543\n",
      "Iteration : 170 - Train Loss : 0.530297, Val Loss : 0.563297, Train F1 : 0.524014, Val F1 : 0.396889\n",
      "Iteration : 180 - Train Loss : 0.679345, Val Loss : 0.565590, Train F1 : 0.545762, Val F1 : 0.386925\n",
      "Best Model Saved\n",
      "Iteration : 190 - Train Loss : 0.635504, Val Loss : 0.574211, Train F1 : 0.455347, Val F1 : 0.403391\n",
      "Best Model Saved\n",
      "Iteration : 200 - Train Loss : 0.524858, Val Loss : 0.580209, Train F1 : 0.560224, Val F1 : 0.406604\n",
      "Iteration : 210 - Train Loss : 0.423959, Val Loss : 0.568181, Train F1 : 0.549383, Val F1 : 0.402000\n",
      "Iteration : 220 - Train Loss : 0.444238, Val Loss : 0.563024, Train F1 : 0.567529, Val F1 : 0.401340\n",
      "Best Model Saved\n",
      "Iteration : 230 - Train Loss : 0.463601, Val Loss : 0.567516, Train F1 : 0.589964, Val F1 : 0.411189\n",
      "Iteration : 240 - Train Loss : 0.716977, Val Loss : 0.554688, Train F1 : 0.565631, Val F1 : 0.393841\n",
      "Epoch 2 Started...\n",
      "Iteration : 10 - Train Loss : 0.409702, Val Loss : 0.566864, Train F1 : 0.533023, Val F1 : 0.384083\n",
      "Iteration : 20 - Train Loss : 0.573665, Val Loss : 0.565650, Train F1 : 0.691919, Val F1 : 0.396757\n",
      "Iteration : 30 - Train Loss : 0.432421, Val Loss : 0.575103, Train F1 : 0.696825, Val F1 : 0.403259\n",
      "Iteration : 40 - Train Loss : 0.540865, Val Loss : 0.583707, Train F1 : 0.550372, Val F1 : 0.381761\n",
      "Iteration : 50 - Train Loss : 0.455399, Val Loss : 0.590344, Train F1 : 0.774603, Val F1 : 0.379829\n",
      "Iteration : 60 - Train Loss : 0.685716, Val Loss : 0.594640, Train F1 : 0.723304, Val F1 : 0.409136\n",
      "Iteration : 70 - Train Loss : 0.390183, Val Loss : 0.593731, Train F1 : 0.719017, Val F1 : 0.400308\n",
      "Iteration : 80 - Train Loss : 0.500604, Val Loss : 0.587104, Train F1 : 0.559140, Val F1 : 0.404892\n",
      "Iteration : 90 - Train Loss : 0.462493, Val Loss : 0.579974, Train F1 : 0.565723, Val F1 : 0.404217\n",
      "Iteration : 100 - Train Loss : 0.714666, Val Loss : 0.581080, Train F1 : 0.465179, Val F1 : 0.398265\n",
      "Iteration : 110 - Train Loss : 0.614910, Val Loss : 0.576696, Train F1 : 0.528986, Val F1 : 0.394075\n",
      "Iteration : 120 - Train Loss : 0.597810, Val Loss : 0.568020, Train F1 : 0.673333, Val F1 : 0.402490\n",
      "Iteration : 130 - Train Loss : 0.267690, Val Loss : 0.583117, Train F1 : 0.634339, Val F1 : 0.399321\n",
      "Iteration : 140 - Train Loss : 0.513026, Val Loss : 0.591662, Train F1 : 0.556022, Val F1 : 0.392216\n",
      "Iteration : 150 - Train Loss : 0.456363, Val Loss : 0.594917, Train F1 : 0.622947, Val F1 : 0.398721\n",
      "Iteration : 160 - Train Loss : 0.404453, Val Loss : 0.582347, Train F1 : 0.708812, Val F1 : 0.396495\n",
      "Iteration : 170 - Train Loss : 0.582110, Val Loss : 0.574691, Train F1 : 0.683791, Val F1 : 0.406672\n",
      "Iteration : 180 - Train Loss : 0.768999, Val Loss : 0.588171, Train F1 : 0.482924, Val F1 : 0.407296\n",
      "Iteration : 190 - Train Loss : 0.542440, Val Loss : 0.568821, Train F1 : 0.679211, Val F1 : 0.408562\n",
      "Iteration : 200 - Train Loss : 0.865219, Val Loss : 0.561304, Train F1 : 0.365714, Val F1 : 0.407990\n",
      "Iteration : 210 - Train Loss : 0.656577, Val Loss : 0.569297, Train F1 : 0.524531, Val F1 : 0.408039\n",
      "Best Model Saved\n",
      "Iteration : 220 - Train Loss : 0.643307, Val Loss : 0.580032, Train F1 : 0.743210, Val F1 : 0.411878\n",
      "Iteration : 230 - Train Loss : 0.731152, Val Loss : 0.596847, Train F1 : 0.450893, Val F1 : 0.411447\n",
      "Iteration : 240 - Train Loss : 0.600616, Val Loss : 0.586097, Train F1 : 0.558025, Val F1 : 0.401367\n",
      "Epoch 3 Started...\n",
      "Iteration : 10 - Train Loss : 0.412303, Val Loss : 0.622229, Train F1 : 0.935214, Val F1 : 0.386047\n",
      "Iteration : 20 - Train Loss : 0.481066, Val Loss : 0.618611, Train F1 : 0.685824, Val F1 : 0.398960\n",
      "Iteration : 30 - Train Loss : 0.267191, Val Loss : 0.605974, Train F1 : 0.955840, Val F1 : 0.390523\n",
      "Iteration : 40 - Train Loss : 0.328396, Val Loss : 0.612903, Train F1 : 0.601852, Val F1 : 0.401998\n",
      "Iteration : 50 - Train Loss : 0.468614, Val Loss : 0.668653, Train F1 : 0.774074, Val F1 : 0.394416\n",
      "Iteration : 60 - Train Loss : 0.617498, Val Loss : 0.638766, Train F1 : 0.633005, Val F1 : 0.394711\n",
      "Iteration : 70 - Train Loss : 0.408746, Val Loss : 0.641316, Train F1 : 0.467742, Val F1 : 0.374977\n",
      "Iteration : 80 - Train Loss : 0.381146, Val Loss : 0.636770, Train F1 : 0.788889, Val F1 : 0.394681\n",
      "Iteration : 90 - Train Loss : 0.326978, Val Loss : 0.616377, Train F1 : 0.930881, Val F1 : 0.405879\n",
      "Iteration : 100 - Train Loss : 0.392391, Val Loss : 0.601607, Train F1 : 0.590779, Val F1 : 0.402326\n",
      "Iteration : 110 - Train Loss : 0.585081, Val Loss : 0.597392, Train F1 : 0.610317, Val F1 : 0.398334\n",
      "Iteration : 120 - Train Loss : 0.206355, Val Loss : 0.599936, Train F1 : 0.977753, Val F1 : 0.403099\n",
      "Iteration : 130 - Train Loss : 0.341284, Val Loss : 0.602787, Train F1 : 0.750000, Val F1 : 0.393729\n",
      "Iteration : 140 - Train Loss : 0.579307, Val Loss : 0.610484, Train F1 : 0.545588, Val F1 : 0.398266\n",
      "Best Model Saved\n",
      "Iteration : 150 - Train Loss : 0.493711, Val Loss : 0.645769, Train F1 : 0.842365, Val F1 : 0.439559\n",
      "Best Model Saved\n",
      "Iteration : 160 - Train Loss : 0.336234, Val Loss : 0.584761, Train F1 : 0.909357, Val F1 : 0.453251\n",
      "Iteration : 170 - Train Loss : 0.742497, Val Loss : 0.600107, Train F1 : 0.504762, Val F1 : 0.400205\n",
      "Iteration : 180 - Train Loss : 0.756706, Val Loss : 0.620495, Train F1 : 0.412896, Val F1 : 0.370116\n",
      "Iteration : 190 - Train Loss : 0.468232, Val Loss : 0.632765, Train F1 : 0.696825, Val F1 : 0.398137\n",
      "Iteration : 200 - Train Loss : 0.496319, Val Loss : 0.650599, Train F1 : 0.778764, Val F1 : 0.448315\n",
      "Iteration : 210 - Train Loss : 0.388737, Val Loss : 0.619157, Train F1 : 0.774449, Val F1 : 0.444507\n",
      "Iteration : 220 - Train Loss : 0.291262, Val Loss : 0.632912, Train F1 : 0.635789, Val F1 : 0.394681\n",
      "Iteration : 230 - Train Loss : 0.563538, Val Loss : 0.621968, Train F1 : 0.571111, Val F1 : 0.382141\n",
      "Iteration : 240 - Train Loss : 0.555357, Val Loss : 0.605810, Train F1 : 0.683622, Val F1 : 0.395367\n",
      "Epoch 4 Started...\n",
      "Iteration : 10 - Train Loss : 0.180117, Val Loss : 0.592426, Train F1 : 0.968473, Val F1 : 0.445724\n",
      "Iteration : 20 - Train Loss : 0.406227, Val Loss : 0.626368, Train F1 : 0.790681, Val F1 : 0.419433\n",
      "Iteration : 30 - Train Loss : 0.330989, Val Loss : 0.692165, Train F1 : 0.738095, Val F1 : 0.431894\n",
      "Iteration : 40 - Train Loss : 0.472819, Val Loss : 0.665488, Train F1 : 0.722222, Val F1 : 0.429305\n",
      "Iteration : 50 - Train Loss : 0.245397, Val Loss : 0.720791, Train F1 : 0.874359, Val F1 : 0.417780\n",
      "Iteration : 60 - Train Loss : 0.605386, Val Loss : 0.698537, Train F1 : 0.496176, Val F1 : 0.387531\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration : 70 - Train Loss : 0.503499, Val Loss : 0.697541, Train F1 : 0.736257, Val F1 : 0.392606\n",
      "Iteration : 80 - Train Loss : 0.492098, Val Loss : 0.699319, Train F1 : 0.783838, Val F1 : 0.431194\n",
      "Iteration : 90 - Train Loss : 0.496736, Val Loss : 0.757668, Train F1 : 0.684211, Val F1 : 0.428463\n",
      "Iteration : 100 - Train Loss : 0.486588, Val Loss : 0.718456, Train F1 : 0.698618, Val F1 : 0.442672\n",
      "Iteration : 110 - Train Loss : 0.467402, Val Loss : 0.677607, Train F1 : 0.814243, Val F1 : 0.448388\n"
     ]
    }
   ],
   "source": [
    "model.train(train_loader, val_loader, epochs=epochs, lr=lr, weight_decay=weight_decay)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
