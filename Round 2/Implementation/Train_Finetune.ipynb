{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataset import *\n",
    "from train import *\n",
    "\n",
    "import csv, random\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "random.seed(1234)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir = '../../data/.train/.task148/data/train/images/'\n",
    "train_csv = '../../data/.train/.task148/data/train/train.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distributions = {}\n",
    "labels = ['10_콘크리트외벽', '20_조적외벽', '30_판넬외벽', '40_유리외벽', '50_기타외벽']\n",
    "idxs = {29: ['0', '1', '2'], 31: ['0', '1'], 32: ['0', '1'], 36: ['', '부속건축물', '주건축물'], \n",
    "        44: ['', ' ', '강파이프구조', '경량철골구조', '공업화박판강구조(PEB)', '기타강구조', '기타구조', '기타조적구조', '기타철골철근콘크리트구조', '기타콘크리트구조', '목구조', '벽돌구조', '블록구조', '석구조', '시멘트블럭조', '일반목구조', '일반철골구조', '조립식판넬조', '조적구조', '철골구조', '철골철근콘크리트구조', '철골철근콘크리트합성구조', '철골콘크리트구조', '철근콘크리트구조', '콘크리트구조', '통나무구조', '트러스구조', '프리케스트콘크리트구조'], \n",
    "        50: ['', ' ', '(철근)콘크리트', '기와', '기타지붕', '슬레이트']}\n",
    "\n",
    "with open(train_csv, 'r') as csvfile:\n",
    "    for i, line in enumerate(csv.reader(csvfile)):\n",
    "        if i != 0:\n",
    "            ID = line[0]\n",
    "            usage_list = []\n",
    "            for idx in idxs:\n",
    "                usage = [0]*len(idxs[idx])\n",
    "                usage[idxs[idx].index(line[idx])] = 1\n",
    "                usage_list += usage\n",
    "            target = line[67]\n",
    "            target = labels.index(target)\n",
    "            \n",
    "            if target not in distributions: distributions[target] = []\n",
    "            distributions[target].append((ID, tuple(usage_list), target))\n",
    "\n",
    "            \n",
    "distributions[0] = random.sample(distributions[0], 4800)\n",
    "#distributions[4] = random.sample(distributions[4], 4800)\n",
    "\n",
    "for distribution in sorted(distributions):\n",
    "    print(distribution, len(distributions[distribution]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = set()\n",
    "val_set = set()\n",
    "\n",
    "for i in range(len(labels)):\n",
    "    temp = random.sample(distributions[i], len(distributions[i])//4)\n",
    "    train_set.update(set(distributions[i])-set(temp))\n",
    "    val_set.update(temp)\n",
    "    \n",
    "train = list(train_set)\n",
    "val = list(val_set)\n",
    "\n",
    "print(len(train), len(val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "\n",
    "epochs = 10\n",
    "lr = 0.0001\n",
    "weight_decay = 0.000001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transform = transforms.Compose([\n",
    "    transforms.Resize((256, 256)),\n",
    "    transforms.RandomCrop(224),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.5231, 0.5493, 0.5485], std=[0.2502, 0.2544, 0.2786])])\n",
    "\n",
    "val_transform = transforms.Compose([\n",
    "    transforms.Resize((256, 256)),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.5231, 0.5493, 0.5485], std=[0.2502, 0.2544, 0.2786])])\n",
    "\n",
    "\n",
    "train_dataset = Train_148(infos=train, transform=train_transform)\n",
    "val_dataset = Train_148(infos=val, transform=val_transform)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = torch.utils.data.DataLoader(val_dataset, batch_size=128, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Baseline(num_input=len(usage_list), num_classes=len(labels), save='./meta_')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.train(train_loader, val_loader, epochs=epochs, lr=lr, weight_decay=weight_decay)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
